{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Parallel Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Python Notebook concerning the final version containing the coding for the Only-Parallel (Supervised) version of the program. It is to be completed with the correct format of the Contextual and Style Classifiers in their corresponding parts.\n",
    "\n",
    "Date of upload: Friday 31th January\n",
    "\n",
    "Actual Version: 2.1, translation implemented (Monday 10th February)\n",
    "\n",
    "Precedent Versions : 2.0, 1.1, 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "from scripts.data_builders.prepare_dataset import prepare_dataset,string2code,code2string\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device = \",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ...\n",
      "- Shakespeare dataset length :  21079\n",
      "- Corrupted samples (ignored) :  0\n"
     ]
    }
   ],
   "source": [
    "train_data, dict_words = prepare_dataset(\"data/shakespeare.csv\",device,ratio=0.5,shuffle_ctx=False) #check with shift+tab to look at the data structure\n",
    "batch_size = 64\n",
    "dict_token = {b:a for a,b in dict_words.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self,model,optim):\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.epoch = 0\n",
    "savepath = Path(\"data/models/embedding_v1\")\n",
    "embedding = torch.load(savepath).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_heads = 4\n",
    "d_feedforward = 1024\n",
    "batch_size = 64\n",
    "dict_size = len(dict_token)\n",
    "\n",
    "d_embedding = embedding.embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Classifier (To be filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "savepath_style = Path(\"data/models/coherence_classifier_v1_epoch_100\")\n",
    "coherence_classifier = torch.load(savepath_style).to(device)\n",
    "coherence_classifier.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style classifier (To be filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath_style = Path(\"data/models/style_classifier_v1\")\n",
    "style_classifier = torch.load(savepath_style).to(device)\n",
    "style_classifier.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (To be adapted once we have the Context and Style Class For the Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelModel(torch.nn.Module):\n",
    "    def __init__(self,dict_size, d_embedding, nb_heads, d_feedforward):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_layer = torch.nn.Embedding(dict_size+1, d_embedding, padding_idx=dict_size)\n",
    "        self.positional_layer = PositionalEncoding(d_embedding)\n",
    "        self.sentence_encoder = torch.nn.TransformerEncoderLayer(d_model = d_embedding, nhead = nb_heads, \n",
    "                                                    dim_feedforward = d_feedforward)\n",
    "        self.context_encoder = torch.nn.TransformerEncoderLayer(d_model = d_embedding, nhead = nb_heads, \n",
    "                                                    dim_feedforward = d_feedforward)\n",
    "        self.sentence_decoder = torch.nn.TransformerDecoderLayer(d_model = d_embedding, nhead = nb_heads, \n",
    "                                                    dim_feedforward = d_feedforward)\n",
    "        self.label_embedding = torch.nn.Embedding(2,768)\n",
    "    \n",
    "    \n",
    "    def _generate_square_subsequent_mask(self,sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def forward(self,x,ctx_x,y,label_x):\n",
    "        device = x.device\n",
    "        mask_x = self._generate_square_subsequent_mask(x.shape[1]).to(device)\n",
    "        mask_ctx = self._generate_square_subsequent_mask(ctx_x.shape[1]).to(device)\n",
    "        mask_y = self._generate_square_subsequent_mask(y.shape[1]).to(device)\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embed_layer(x).transpose(0,1) # token x batch x embedding\n",
    "        ctx_x = self.embed_layer(ctx_x).transpose(0,1)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        x = self.positional_layer(x)\n",
    "        ctx_x = self.positional_layer(ctx_x)        \n",
    "        \n",
    "        # Encoders\n",
    "        x_enc = self.sentence_encoder(x,mask_x)\n",
    "        ctx_enc = self.context_encoder(ctx_x,mask_ctx)\n",
    "\n",
    "        # Linear and Style Mixing\n",
    "        x_and_ctx = torch.cat((x_enc,ctx_enc),dim = 0)\n",
    "        label = (1-label_x).reshape((1,x_and_ctx.shape[1])).expand((x_and_ctx.shape[0],x_and_ctx.shape[1]))\n",
    "        x_lab = x_and_ctx + self.label_embedding(label)\n",
    "        \n",
    "        # Decoder\n",
    "        y = self.embed_layer(y)\n",
    "        y_pos = self.positional_layer(y.transpose(0,1))\n",
    "        y_pred = self.sentence_decoder(y_pos,x_lab,mask_y)\n",
    "        \n",
    "        return(y_pred.transpose(0,1),y)\n",
    "    \n",
    "    def translator(self,x,ctx_x,y,label_x):\n",
    "        device = x.device\n",
    "        mask_x = self._generate_square_subsequent_mask(x.shape[1]).to(device)\n",
    "        mask_ctx = self._generate_square_subsequent_mask(ctx_x.shape[1]).to(device)\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embed_layer(x).transpose(0,1) # token x batch x embedding\n",
    "        ctx_x = self.embed_layer(ctx_x).transpose(0,1)\n",
    "        \n",
    "        # Positional Encoding\n",
    "        x = self.positional_layer(x)\n",
    "        ctx_x = self.positional_layer(ctx_x)        \n",
    "        \n",
    "        # Encoders\n",
    "        x_enc = self.sentence_encoder(x,mask_x)\n",
    "        ctx_enc = self.context_encoder(ctx_x,mask_ctx)\n",
    "        \n",
    "        # Linear and Style Mixing\n",
    "        x_and_ctx = torch.cat((x_enc,ctx_enc),dim = 0)\n",
    "        label = (1-label_x).reshape((1,x_and_ctx.shape[1])).expand((x_and_ctx.shape[0],x_and_ctx.shape[1]))\n",
    "        x_lab = x_and_ctx + self.label_embedding(label)\n",
    "        return(x_lab)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training  (To be adapted once we have the Context and Style Class For the Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the model(s)\n",
    "\n",
    "model = ParallelModel(dict_size, d_embedding, nb_heads, d_feedforward).to(device)\n",
    "model.embed_layer = embedding\n",
    "model.embed_layer.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information concerning the Training optimizer\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "decoder_linear = torch.nn.Linear(d_embedding,dict_size).to(device)\n",
    "softmax_layer = torch.nn.LogSoftmax(dim = 2).to(device)\n",
    "\n",
    "params = list(model.parameters()) + list(decoder_linear.parameters())#+ list(context_encoder.parameters()) + \n",
    "                                  #list(linear_context.parameters) + list(sentence_decoder.parameters())\n",
    "\n",
    "l_r = 5e-2\n",
    "optimizer=Adam(params,lr=l_r)\n",
    "\n",
    "#Weights of the losses\n",
    "l1=1 #\n",
    "l2=1e-2\n",
    "l3=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses \n",
    "loss_seq2seq = torch.nn.SmoothL1Loss(reduction='mean') #Contextual Seq2Seq Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2197,  7850,  3303,  ...,  4679,  4679,  4679],\n",
      "        [ 6667,  3303,  2566,  ...,  7850,  4679,  4679],\n",
      "        [ 7411, 15929,  4216,  ...,  8991,  4679,  4679],\n",
      "        ...,\n",
      "        [ 5962, 11337,  1166,  ..., 12458,  4679,  4679],\n",
      "        [ 2826,  2397,  3846,  ...,  4249,  7850,  4679],\n",
      "        [ 7411,  8405, 14557,  ...,  8991,  4679,  8991]], device='cuda:0')\n",
      "torch.Size([64, 51])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-94616972c9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Style class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss_sty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstyle_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyle_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mloss_sty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_sty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         distilbert_output = self.distilbert(\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         )\n\u001b[1;32m    633\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistilbert_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (bs, seq_len, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mtfmr_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfmr_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtfmr_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Self-Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0msa_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0msa_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa_output\u001b[0m  \u001b[0;31m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mContextualized\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0monly\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \"\"\"\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mk_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "nb_epoch = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                            shuffle=True,collate_fn=train_data.collate)\n",
    "n = len(train_data.x) // batch_size\n",
    "loss_graph = []\n",
    "loss_style_list = []\n",
    "loss_seq_list = []\n",
    "for epoch in range(nb_epoch):\n",
    "    total_loss = 0\n",
    "    total_style = 0\n",
    "    total_seq = 0\n",
    "    i = 0\n",
    "    for x,y, ctx_x, ctx_y_1,ctx_y_2, label_x in train_loader:\n",
    "        i += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred, y = model.forward(x,ctx_x,y,label_x) #Output still embedded \n",
    "        \n",
    "        # Seq2Seq Loss with Token\n",
    "        \n",
    "        loss_seq = l1*loss_seq2seq(y_pred,y)\n",
    "        \n",
    "        # Argmax\n",
    "        y_pred = decoder_linear(y_pred)\n",
    "        y_pred = torch.argmax(softmax_layer(y_pred),dim = 2)\n",
    "        print(y_pred)\n",
    "        print(y_pred.shape)\n",
    "        # Style class\n",
    "        loss_sty,style_pred = style_classifier.forward(inputs_embeds=y_pred,)\n",
    "        loss_sty = l2*loss_sty\n",
    "        \n",
    "        # Coherence class\n",
    "        #loss_coh,coh_pred = coherence_classifier()\n",
    "        #loss_sty = l2*loss_sty\n",
    "        \n",
    "        # Step\n",
    "        \n",
    "        loss = loss_seq + loss_sty # + loss_coh\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_style += loss_sty.item()\n",
    "        total_seq += loss_seq.item()\n",
    "        if(i == 1 or i%5 == 0 or i == n):\n",
    "          print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                'loss {:5.2f} | loss_seq  {:5.2f} | loss_style {:5.2f} | '\n",
    "                'total loss {:5.2f} | l_rate {:.0e}'.format(\n",
    "                  epoch+1, i, n+1,loss.item(),loss_seq.item(),loss_sty.item(),\n",
    "                    total_loss/i,optimizer.param_groups[0][\"lr\"]))\n",
    "        loss_graph += [total_loss/i]\n",
    "        loss_style_list += [total_style/i]\n",
    "        loss_seq_list += [total_seq/i]\n",
    "    print('-' * 70)\n",
    "    print(\"Epoch \",epoch+1,\"\\t\",round(total_loss / n,2))\n",
    "    print('-' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHALLENGES'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_token[4679]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reduction = 'sum' l_r = 5e-4\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "rango = np.arange(len(loss_graph))\n",
    "plt.figure(1,figsize=(16,16))\n",
    "plt.subplot(231)\n",
    "plt.plot(rango,loss_graph)\n",
    "plt.title(\"Total Loss\")\n",
    "plt.grid()\n",
    "plt.subplot(234)\n",
    "plt.plot(rango,loss_graph)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Total Loss Log\")\n",
    "plt.grid()\n",
    "plt.subplot(232)\n",
    "plt.plot(rango,loss_seq_list)\n",
    "plt.title(\"Seq Loss\")\n",
    "plt.grid()\n",
    "plt.subplot(235)\n",
    "plt.plot(rango,loss_seq_list)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"Seq Loss Log\")\n",
    "plt.grid()\n",
    "plt.subplot(233)\n",
    "plt.plot(rango,loss_style_list)\n",
    "plt.title(\"Style Loss\")\n",
    "plt.grid()\n",
    "plt.subplot(236)\n",
    "plt.plot(rango,loss_style_list)\n",
    "plt.title(\"Style Loss Log\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Phrase I HAVE A MIND TO STRIKE THEE ERE\n",
      "Target phrase I HAVE HALF A MIND TO HIT YOU BEFORE YOU SPEAK\n",
      "Original Style : Shakespearian\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 13])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,ctx_x,_,_,_,_,_,label_x,_ = train_data[0]\n",
    "print(\"Original Phrase\",code2string(x,dict_token))\n",
    "print(\"Target phrase\",code2string(y,dict_token))\n",
    "if(label_x.item() == 1):\n",
    "    print(\"Original Style : Shakespearian\")\n",
    "else:\n",
    "    print(\"Original Style : Modern\")\n",
    "x.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with: <SOS> \n",
      "torch.Size([1, 1])\n",
      "tensor([15183])\n",
      "Produced phrase: <SOS> AMPLE \n",
      "torch.Size([1, 2])\n",
      "tensor([15183])\n",
      "Produced phrase: <SOS> AMPLE AMPLE \n",
      "torch.Size([1, 3])\n",
      "tensor([15183])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE \n",
      "torch.Size([1, 4])\n",
      "tensor([15241])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY \n",
      "torch.Size([1, 5])\n",
      "tensor([10566])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE \n",
      "torch.Size([1, 6])\n",
      "tensor([15183])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE \n",
      "torch.Size([1, 7])\n",
      "tensor([10566])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE \n",
      "torch.Size([1, 8])\n",
      "tensor([10566])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE \n",
      "torch.Size([1, 9])\n",
      "tensor([15241])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY \n",
      "torch.Size([1, 10])\n",
      "tensor([64])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN \n",
      "torch.Size([1, 11])\n",
      "tensor([10566])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE \n",
      "torch.Size([1, 12])\n",
      "tensor([12599])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY \n",
      "torch.Size([1, 13])\n",
      "tensor([15183])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY AMPLE \n",
      "torch.Size([1, 14])\n",
      "tensor([15241])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY AMPLE BERKELEY \n",
      "torch.Size([1, 15])\n",
      "tensor([4536])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY AMPLE BERKELEY ESTATE \n",
      "torch.Size([1, 16])\n",
      "tensor([10566])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY AMPLE BERKELEY ESTATE DO-DE \n",
      "torch.Size([1, 17])\n",
      "tensor([15241])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY AMPLE BERKELEY ESTATE DO-DE BERKELEY \n",
      "torch.Size([1, 18])\n",
      "tensor([10566])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY AMPLE BERKELEY ESTATE DO-DE BERKELEY DO-DE \n",
      "torch.Size([1, 19])\n",
      "tensor([10566])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY AMPLE BERKELEY ESTATE DO-DE BERKELEY DO-DE DO-DE \n",
      "torch.Size([1, 20])\n",
      "tensor([10566])\n",
      "Produced phrase: <SOS> AMPLE AMPLE AMPLE BERKELEY DO-DE AMPLE DO-DE DO-DE BERKELEY THAN DO-DE NOTARY AMPLE BERKELEY ESTATE DO-DE BERKELEY DO-DE DO-DE DO-DE \n"
     ]
    }
   ],
   "source": [
    "    #Generation de phrase \n",
    "with torch.no_grad():\n",
    "        h_t = model.translator(x.unsqueeze(0),ctx_x.unsqueeze(0),y.unsqueeze(0),label_x.unsqueeze(0))\n",
    "        phrase = torch.tensor([[0]])\n",
    "        print(\"Starting with: \",end='')\n",
    "        for p in phrase:\n",
    "            print(dict_token[p.item()],end=' ')\n",
    "        print(\"\")\n",
    "        i = 0\n",
    "        limit = 20\n",
    "        flag = False\n",
    "        while(not(flag) and i != limit):\n",
    "            #mask = model._generate_square_subsequent_mask(phrase.shape[1])\n",
    "            y_aux = model.embed_layer(phrase)\n",
    "            y_pos = model.positional_layer(y_aux)\n",
    "            y_pred = model.sentence_decoder(y_pos,h_t).transpose(0,1)\n",
    "            y_pred = decoder_linear(y_pred)\n",
    "            y_pred = torch.argmax(softmax_layer(y_pred),dim = 2)\n",
    "            phrase = torch.cat((phrase,y_pred[:,-1].reshape((1,1))),0)\n",
    "            i += 1\n",
    "        print(\"Produced phrase: \",end='')\n",
    "        for p in phrase:\n",
    "            print(dict_token[p.item()],end=' ')\n",
    "        print(\"\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
